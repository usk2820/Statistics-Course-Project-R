---
title: "718 Project"
author: "Umer"
date: "4/5/2022"
output: html_document
---


Section 1.Q1-part(a)
```{r}
myFunc = function(lamda,t) #introducing function for part a which takes value of lamda and time to return output
{
n=2* qpois(0.9999999, t*lamda) #using qpois and multiply it by 2 to have a same count
exp_dist = cumsum(rexp(n, lamda)) #cumulative exponential distribution with n calculated in previous step
#exp_dist
patient_arrival = c() #introducing vector of patient arrival times
for(i in 1:length(exp_dist)) #storing values of the cumulative exponential distribution in the patient arrival time vector
{
  if(exp_dist[i] <= t) #store values only if the patient arrives before 4 pm.
  {
    patient_arrival[i] = exp_dist[i]
  }
  else 
    break
}
#patient_arrival
  
patients_waited = 0         # patients who have had to wait
total_wait = 0     # total waiting time so far
doctor <- c(patient_arrival[1], patient_arrival[1], patient_arrival[1]) # next time at which each doctor is free to see another patient
#doctor
#min(doctor)
for(i in 1:length(patient_arrival)){ #running loop for each patient arriving at the clinic
  w=0 # setting initial wait time for each patient
  patient_arrival[i]=patient_arrival[i]+total_wait #patient arrival plus the time he had to wait because of previous waiting patients
    for(j in 1:length(doctor)){ #running loop for each doctor to see if anyone's free
      if(patient_arrival[i]>=doctor[j]){ #if doctor free.. assign him the time of patient arrival time
        doctor[j]=patient_arrival[i]
      }
    }
  w= max((min(doctor)-patient_arrival[i]),0) # checking how much the patient had to wait for
  total_wait= total_wait+ w #adding patient wait time to total wait time
  if(w>0) 
  {
  patients_waited =patients_waited+1 #if patient has to wait, then add one to the number of patients who have had to wait
  i=i-1 #run loop again for the same patient
  }
  else
  {
    for(j in 1:length(doctor)){ #if patient does not have to wait then assign doctor to that patient
      if(patient_arrival[i]>=doctor[j])
        {
        doctor[j]=patient_arrival[i]+runif(1,5,20)
        break
      }
    }
  }
}
total_patients=length(patient_arrival) #total number of patients is the length of the vector of patients arrival
#patients_waited #patients that had to wait
(if(patients_waited==0){ #if no patients waited then the average wait will be equal to 0
  avg_wait=0
}
else{ # If patients had to wait then calculate the average waiting time
avg_wait=total_wait/patients_waited})
closing_time=max(doctor)

output=c(total_patients, patients_waited , avg_wait, closing_time) #store results in vector
return(output) #return results
}
t <- (16 - 9) * 60 #time value
lamda =1/10 # lamda value
x=myFunc(lamda,t) # calling function and storing in x
#x
{ # output results
cat("number of patients: ",x[1], "  ")
cat("number of patients waited: ",x[2], "  ")
cat("average patient wait: ",x[3], "  ") #average patient wait of the patients who waited
cat("Closing time of clinic: ",9+x[4]/60, "pm  ") #changing time to hours
}

```
answer to part(a) returns different values every time because patients arrival time to the clinic is different every time since running the exponential distribution gives different values.

Section 1,Q1. part (b)
```{r}
{
#introducing empty vectors to store values
total_patients_x=c()
n_waited_x=c()
avg_wait_x=c()
closing_time_x=c()

for(i in 1:1000) #run 1000 times to store values in the vectors
{
  y=myFunc(lamda,t)
  total_patients_x[i]=y[1] #storing values in each vector
  n_waited_x[i]=y[2]
  avg_wait_x[i]=y[3]
  closing_time_x[i]=y[4]
  
}
#median(total_patients_x)
#median(n_waited_x)
#median(avg_wait_x)
#median(closing_time_x)
#output results of part b
cat("median number of patients: ",median(total_patients_x), "  ")
cat("median number of patients waited: ",median(n_waited_x), "  ")
cat("median average patient wait: ",median(avg_wait_x), "  ")
cat("median Closing time of clinic: ",median(9+closing_time_x/60), "pm  ")
}
```
Running part b almost gives similar values each time it is run.

Section 2. Question 1 part a
```{r}
#install.packages('haven')
library(haven)
library(foreign)
library("dplyr")

data1 <- read.dta("Q1Data1.dta") # read data for Q1
#summary(data1$state)
#subset the data removing the states hawaii, washington dc and alaska and only show 4 columns(state,marital, heat 2, heat4)
newdata1 <- subset(data1, state != "hawaii" & state!="washington dc"& state!="alaska", select = c(state, marital, heat2, heat4))
#summary(newdata1)
#newdata1$heat2 <- as.character((newdata1$heat2))
#newdata1$heat4 <- as.character((newdata1$heat4))
#replace heat 2 with heat 4 if heat 2 is na
newdata1$heat2 <- ifelse(is.na(as.character(newdata1$heat2)), as.character(newdata1$heat4) , as.character(newdata1$heat2))
#summary(newdata1)
#remove rows if heat 2 is empty
newdata1 <- subset(newdata1, heat2 != "")
#summary(newdata1)
#subset data with heat 2 having only 2 votes
newdata1 <- subset(newdata1, heat2 == "dem/lean dem"| heat2 == "rep/lean rep")
#summary(newdata1)
newdata1$marital <- as.character(newdata1$marital) #changing marital column to character
newdata1["marital"][newdata1["marital"] != "married"] = "other" #replace any other status except married to other
#summary(newdata1)
newdata1 <- subset(newdata1, marital != "") #remove rows where marital status is not known
newdata1$marital <- as.factor(newdata1$marital) #changing marital back to factor
newdata1$heat2 <- as.factor(newdata1$heat2)#changing heat2 back to factor
summary(newdata1) #summary of the data

```
Data has been cleaned and now only represents 4 columns. The summary of the data can be seen above.

Section 2. Question 1 part b
```{r}
#newdata1
states = unique(newdata1$state) #making a states vector
#states
votecount=matrix(NA,nrow = length(unique(newdata1$state)), ncol =8) #make new matrix to store values
for (i in 1:length(states)) #run for loop for all states
{
  votecount[i,1] = sum(newdata1$state == states[i]) #calculating sum of all voters in a state
  #calculating sum of all voters in a state that are married
  votecount[i,2] = sum((newdata1$state == states[i]) & (newdata1$marital == "married")) 
  #calculating sum of all voters in a state that are non-married
  votecount[i,3] = sum((newdata1$state == states[i]) & (newdata1$marital == "other"))
  #calculating proportion of all democratic voters in a state in percentage
  votecount[i,4] = 100*(sum((newdata1$state == states[i]) & (newdata1$heat2 == "dem/lean dem")))/votecount[i,1]
  #calculating proportion of all married voters in a state in percentage
  votecount[i,5] = 100*sum((newdata1$state == states[i]) & (newdata1$marital == "married"))/votecount[i,1]
  #calculating proportion of all democratic voters in a state that are married in percentage
  votecount[i,6] = 100*sum((newdata1$state == states[i]) & (newdata1$heat2 == "dem/lean dem")& (newdata1$marital == "married"))/votecount[i,2]
  #calculating proportion of all democratic voters in a state that are non-married in percentage
  votecount[i,7] = 100*sum((newdata1$state == states[i]) & (newdata1$heat2 == "dem/lean dem")& (newdata1$marital == "other"))/votecount[i,3]
  #difference in democratic married and democratic non-married
  votecount[i,8] = votecount[i,6]-votecount[i,7]
}
rownames(votecount)=states #setting row names to states
#setting column names
colnames(votecount) <- c("vote_state","married","non-married", "dem_supports", "married_ratio","dem_mar","dem_other", "Diff")
#votecount
votecount1=as.data.frame(votecount) #converting matrix to data frame
votecount1=subset(votecount, select=c(dem_supports, married_ratio,dem_mar,dem_other, Diff)) #subset only the results required
votecount1
head(votecount1,5) #output only first 5 rows

```
Values asked in the question are generated by running a for loop in a matrix and then the matrix was changed to a data frame. Inital 5 rows output can be seen above.

Section 2. Question 1 part c
```{r}
data2 <- read.csv("Q1Data2.csv") #read data
#summary(data2)
#remove the 3 states and subsetting only 2 columns
newdata2 <- subset(data2, state != "Hawaii" & state!="Washington"& state!="Alaska", select = c(state, vote_Obama_pct))
newdata2

```
Filtered data as per the instruction in the question. removed the mentioned states and subset 2 columns only.

Section 2. Question 1 part d
```{r}
library("glmnet")
newdata1d=newdata1
newdata1d$heat2 <- as.character((newdata1d$heat2)) #changing the heat2 column as character
newdata1d$marital <- as.character((newdata1d$marital)) #changing the marital column as character

#assigning 1 and 0 values to both the columns
newdata1d["marital"][newdata1d["marital"] == "married"] = 1 
newdata1d["marital"][newdata1d["marital"] == "other"] = 0
newdata1d["heat2"][newdata1d["heat2"] == "dem/lean dem"] = 1
newdata1d["heat2"][newdata1d["heat2"] == "rep/lean rep"] = 0

newdata1d$marital <- as.numeric(newdata1d$marital)#changing the marital column as numeric
newdata1d$heat2 <- as.numeric(newdata1d$heat2) #changing the heat2 column as numeric
#assumption 1
#logistic regression with marital status (No state level heterogeneity)
glm(heat2  ~ marital, family = binomial, data = newdata1d)
#Assumption 2
#logistic regression with marital status and states as dummy variables (State level heterogeneity)
glm(heat2  ~ marital+ state, family = binomial, data = newdata1d)
#Assumption 3
mmpredict=model.matrix(heat2  ~ marital+ state, family = binomial, data = newdata1d) #predicted values
mmoutcome=newdata1d$heat2

cv_model_ridge=cv.glmnet(x= mmpredict,y=mmoutcome,alpha=0,family="binomial") #cross validation model to find best lambda
best_lamda_ridge= cv_model_ridge$lambda.min #store best lambda

model_ridge=glmnet(x= mmpredict,y=mmoutcome,alpha=0, lamda=best_lamda_ridge, family="binomial") #predict using best lambda values
coef(model_ridge)

predicted_values = as.numeric(predict(model_ridge, s= best_lamda_ridge, newx = mmpredict)) #predicted values for assumption 3
mmoutcome= as.numeric(mmoutcome)
sum((predicted_values- mmoutcome)^2) #sum of squared errors

```
all the 3 models are run and predicted values are calculated for assumption 3 and the sum of squared errors is calculated which is 12540.58

Section 2. Question 1 part e
```{r}
#adding libraries
library("plyr")
library('ggplot2')
library(dplyr)

y_data = as.data.frame(cbind(as.character(newdata1$state), predicted_values)) #data frame for predicted values and states
for (i in 1:nrow(y_data)){
  if (y_data[i,2]>0.5){ #check whether democrat or not and assign values
    y_data[i,"votertype"] = "dem"
  }else{
    y_data[i,"votertype"] = "rep"
  }
}
y_data = y_data %>% #select relevant columns
  select(V1,votertype)
table(y_data)[,1]

count_of_states <- newdata1%>% #count total voters
  group_by(state)%>% #grouping count by states
  summarise(predicted = n())

count_of_dem <- newdata1%>% #count total democratic voters
  filter(heat2 == "dem/lean dem") %>% 
  group_by(state) %>%
  summarise(intended = n())
  

finaldata <- cbind(newdata2,(count_of_dem[,2]/count_of_states[,2])*100,(table(y_data)[,1]/count_of_states[,2])*100) #create dataframe for actual obama pct, democratic proportion, and predicted values

ggplot(finaldata, aes(x = intended, y = vote_Obama_pct)) + geom_point() + geom_point() + geom_text(label = newdata2$state) #plot intended vs actual values
ggplot(finaldata, aes(x = predicted, y = vote_Obama_pct)) + geom_point() + geom_point() + geom_text(label = newdata2$state) #plot predicted vs actual values

```
Plots of actual v intended and actual v predicted can be seen above. District of columbia can be seen having a very different actual value than the predicted and intended.
